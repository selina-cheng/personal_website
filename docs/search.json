[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Selina Cheng",
    "section": "",
    "text": "I’m a second year student studying Statistics and Data Science at UCLA. Currently, I’m an administrative assistant at a network consulting firm. Outside of school, I’m also passionate about music as a percussionist who competes in the national indoor percussion circuit.\n\n\nAdministrative Assistant | New Vision Investments | January 2025 - Present\nData Journalist | Bruin Sports Analytics | September 2024 - April 2024\nUCLA Statistics Department | STATS20 Learning Intern | April 2024 - December\n\n\n  \n  \n  \n    \n     GitHub\n  \n  \n    \n     Email\n  \n  \n    \n     LinkedIn"
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Selina Cheng",
    "section": "",
    "text": "I’m a second year student studying Statistics and Data Science at UCLA. Currently, I’m an administrative assistant at a network consulting firm. Outside of school, I’m also passionate about music as a percussionist who competes in the national indoor percussion circuit.\n\n\nAdministrative Assistant | New Vision Investments | January 2025 - Present\nData Journalist | Bruin Sports Analytics | September 2024 - April 2024\nUCLA Statistics Department | STATS20 Learning Intern | April 2024 - December\n\n\n  \n  \n  \n    \n     GitHub\n  \n  \n    \n     Email\n  \n  \n    \n     LinkedIn"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Selina Cheng",
    "section": "Education",
    "text": "Education\nUniversity of California, Los Angeles | Los Angeles, CA\nB.S. in Statistics and Data Science | Expected June 2026"
  },
  {
    "objectID": "dayton.html",
    "href": "dayton.html",
    "title": "Is WGI World Championships Predictable?",
    "section": "",
    "text": "Use Selenium as a robot to click on all the necessary links and save dynamic HTML for each event in World Championships\nUse pickle to save list to prevent having to run Selenium again.\n\n\nCode\nimport pickle\n\nwith open('dayton_html.pkl', 'wb') as f:\n    pickle.dump(pages, f, pickle.HIGHEST_PROTOCOL)\n\n\n\n\nCode\n# Reload list of HTML data if necessary\nimport pickle\n\nwith open('dayton_html.pkl', 'rb') as f:\n    pages = pickle.load(f)\n\n\nUse BeautifulSoup to parse HTML data and compile it into a data set.\n\n\nCode\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n# List of dataframes storing results from each page\ndfs = []\n\nfor page in pages:\n    doc = BeautifulSoup(page, \"html.parser\")\n    event_name = doc.find_all(id=\"cs-org-scores-header\")\n    rank_col = doc.find_all(\"div\", \"rank\")\n    group_col = doc.find_all(\"div\", \"group\")\n    score_col = doc.find_all(\"div\", \"score\")\n\n    # Create dataframe of this page of data\n    data = {\"Event\": [event_name] * len(rank_col),\n            \"Rank\": rank_col,\n            \"Group\": group_col,\n            \"Score\": score_col}\n    event = pd.DataFrame(data)\n    dfs.append(event)\n\n# Final dataset\nworld_df = pd.concat(dfs, ignore_index = True)"
  },
  {
    "objectID": "dayton.html#questions",
    "href": "dayton.html#questions",
    "title": "Is WGI World Championships Predictable?",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "dayton.html#technical-learning",
    "href": "dayton.html#technical-learning",
    "title": "Is WGI World Championships Predictable?",
    "section": "Technical Learning",
    "text": "Technical Learning\nlearning python syntax enumerate() debugging lots of errors learning DOM and HTML wgi is a dynamic website selenium quirks (can’t click on an element if it’s not visible on the page) basically dont do ANYTHING (finding an element, clikcing elemnt, scorlling to element) until sleenium recognize the leement is loaded StaleElementError different names for World Class finals through all the years.. using IW and Championships will create some duplicates.. but its possible to remove duplicate data :D\ntook like 15 mins to scrape the data LOL not even including 2020-2021 cuz those years did not exist\nRuns through everything! except.. 2016-2017??"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "blog posts",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "stats20.html",
    "href": "stats20.html",
    "title": "STATS20",
    "section": "",
    "text": "How to Use the Apply Family of Functions in R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranslating Math Into R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "stats20/math_notation.html",
    "href": "stats20/math_notation.html",
    "title": "Translating Math Into R",
    "section": "",
    "text": "A guide on converting mathematical expressions and concepts into R code, including  explanations, examples, and best practices."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Selina Cheng",
    "section": "",
    "text": "Administrative Assistant | New Vision Investments | January 2025 - Present\nData Journalist | Bruin Sports Analytics | September 2024 - April 2024\nUCLA Statistics Department | STATS20 Learning Intern | April 2024 - December"
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Selina Cheng",
    "section": "Projects",
    "text": "Projects\nI developed supplemental academic materials for UCLA’s introductory R programming course (STATS20).\nI created a minimalist website for conversations with friends.\nI created a Python clone of one of my favorite games, Minesweeper."
  },
  {
    "objectID": "stats20/apply_family.html",
    "href": "stats20/apply_family.html",
    "title": "How to Use the Apply Family of Functions in R",
    "section": "",
    "text": "A guide for selecting the appropriate apply function in R, explaining when to use apply(), lapply(), sapply(), vapply(), and tapply() based on input data type and desired output format.\n\n\n    It appears you don't have a PDF plugin for this browser.\n    Click here to\n    download the PDF file."
  }
]